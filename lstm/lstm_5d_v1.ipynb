{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.metrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMCADS03</th>\n",
       "      <th>LMCADY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>SPX</th>\n",
       "      <th>BCOM</th>\n",
       "      <th>MXWD</th>\n",
       "      <th>XAU</th>\n",
       "      <th>XAG</th>\n",
       "      <th>LMCADY_acu_5d</th>\n",
       "      <th>LMCADY_std_5d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>0.014218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.008721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.112019</td>\n",
       "      <td>-0.110645</td>\n",
       "      <td>-0.024921</td>\n",
       "      <td>-0.103782</td>\n",
       "      <td>-0.054910</td>\n",
       "      <td>-0.085172</td>\n",
       "      <td>-0.097378</td>\n",
       "      <td>-0.123485</td>\n",
       "      <td>-0.185825</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.008649</td>\n",
       "      <td>-0.008880</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.005469</td>\n",
       "      <td>-0.005554</td>\n",
       "      <td>-0.004878</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.008616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.012148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>0.027541</td>\n",
       "      <td>0.136158</td>\n",
       "      <td>0.066117</td>\n",
       "      <td>0.105134</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.226116</td>\n",
       "      <td>0.259832</td>\n",
       "      <td>0.091981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LMCADS03       LMCADY          DXY          SPX         BCOM  \\\n",
       "count  5539.000000  5539.000000  5539.000000  5539.000000  5539.000000   \n",
       "mean     -0.000185    -0.000178     0.000007    -0.000252     0.000072   \n",
       "std       0.016059     0.016464     0.004793     0.011794     0.010250   \n",
       "min      -0.112019    -0.110645    -0.024921    -0.103782    -0.054910   \n",
       "25%      -0.008649    -0.008880    -0.002635    -0.005469    -0.005554   \n",
       "50%       0.000000     0.000000     0.000000    -0.000390     0.000000   \n",
       "75%       0.007562     0.007760     0.002658     0.003949     0.005375   \n",
       "max       0.109603     0.109134     0.027541     0.136158     0.066117   \n",
       "\n",
       "              MXWD          XAU          XAG  LMCADY_acu_5d  LMCADY_std_5d  \n",
       "count  5539.000000  5539.000000  5539.000000    5539.000000    5539.000000  \n",
       "mean     -0.000205    -0.000274    -0.000106      -0.000867       0.014218  \n",
       "std       0.009880     0.010722     0.019587       0.034782       0.008721  \n",
       "min      -0.085172    -0.097378    -0.123485      -0.185825       0.000805  \n",
       "25%      -0.004878    -0.005978    -0.009770      -0.021102       0.008616  \n",
       "50%      -0.000643    -0.000497    -0.000771      -0.001844       0.012148  \n",
       "75%       0.003807     0.004908     0.008074       0.017065       0.017520  \n",
       "max       0.105134     0.099792     0.226116       0.259832       0.091981  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./input/copper_returns_5d_final.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034782023369004565"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop(columns=['Date','LMCADY_std_5d','LMCADY_acu_5d'])\n",
    "target = data['LMCADY_acu_5d']\n",
    "\n",
    "# desviacion estandar del target\n",
    "std_target = target.std()\n",
    "std_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 1\n",
    "X, y = create_dataset(features, target, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 2ms/step - loss: 8.9338e-04 - rmse: 0.0294 - val_loss: 0.0025 - val_rmse: 0.0440\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2369e-04 - rmse: 0.0282 - val_loss: 0.0024 - val_rmse: 0.0438\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.1507e-04 - rmse: 0.0280 - val_loss: 0.0025 - val_rmse: 0.0443\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0635e-04 - rmse: 0.0279 - val_loss: 0.0025 - val_rmse: 0.0443\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0967e-04 - rmse: 0.0279 - val_loss: 0.0024 - val_rmse: 0.0435\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0401e-04 - rmse: 0.0278 - val_loss: 0.0025 - val_rmse: 0.0438\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0560e-04 - rmse: 0.0280 - val_loss: 0.0025 - val_rmse: 0.0442\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0041e-04 - rmse: 0.0278 - val_loss: 0.0025 - val_rmse: 0.0439\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0958e-04 - rmse: 0.0281 - val_loss: 0.0025 - val_rmse: 0.0439\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0701e-04 - rmse: 0.0280 - val_loss: 0.0025 - val_rmse: 0.0442\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9968e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0437\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0096e-04 - rmse: 0.0279 - val_loss: 0.0025 - val_rmse: 0.0438\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0167e-04 - rmse: 0.0279 - val_loss: 0.0024 - val_rmse: 0.0436\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0634e-04 - rmse: 0.0279 - val_loss: 0.0024 - val_rmse: 0.0436\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 8.0042e-04 - rmse: 0.0279 - val_loss: 0.0025 - val_rmse: 0.0439\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9986e-04 - rmse: 0.0279 - val_loss: 0.0024 - val_rmse: 0.0435\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9958e-04 - rmse: 0.0279 - val_loss: 0.0024 - val_rmse: 0.0437\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9761e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0437\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9895e-04 - rmse: 0.0278 - val_loss: 0.0025 - val_rmse: 0.0439\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9529e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0435\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0154e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0435\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9757e-04 - rmse: 0.0278 - val_loss: 0.0025 - val_rmse: 0.0439\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.9810e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0437\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9805e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0436\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.9442e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0438\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9756e-04 - rmse: 0.0278 - val_loss: 0.0024 - val_rmse: 0.0436\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9633e-04 - rmse: 0.0277 - val_loss: 0.0025 - val_rmse: 0.0441\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.9330e-04 - rmse: 0.0278 - val_loss: 0.0026 - val_rmse: 0.0446\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.9644e-04 - rmse: 0.0278 - val_loss: 0.0025 - val_rmse: 0.0440\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 7.9037e-04 - rmse: 0.0276 - val_loss: 0.0025 - val_rmse: 0.0439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79713c10f8b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 712us/step - loss: 0.0012 - rmse: 0.0320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.032014623284339905"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, rmse = model.evaluate(X_test, y_test)\n",
    "\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
