{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import Huber\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMCADS03</th>\n",
       "      <th>LMCADY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>SPX</th>\n",
       "      <th>BCOM</th>\n",
       "      <th>MXWD</th>\n",
       "      <th>XAU</th>\n",
       "      <th>XAG</th>\n",
       "      <th>LMCADY_acu_5d</th>\n",
       "      <th>LMCADY_std_5d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>0.014218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.008721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.112019</td>\n",
       "      <td>-0.110645</td>\n",
       "      <td>-0.024921</td>\n",
       "      <td>-0.103782</td>\n",
       "      <td>-0.054910</td>\n",
       "      <td>-0.085172</td>\n",
       "      <td>-0.097378</td>\n",
       "      <td>-0.123485</td>\n",
       "      <td>-0.185825</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.008649</td>\n",
       "      <td>-0.008880</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.005469</td>\n",
       "      <td>-0.005554</td>\n",
       "      <td>-0.004878</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.008616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.012148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>0.027541</td>\n",
       "      <td>0.136158</td>\n",
       "      <td>0.066117</td>\n",
       "      <td>0.105134</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.226116</td>\n",
       "      <td>0.259832</td>\n",
       "      <td>0.091981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LMCADS03       LMCADY          DXY          SPX         BCOM  \\\n",
       "count  5539.000000  5539.000000  5539.000000  5539.000000  5539.000000   \n",
       "mean     -0.000185    -0.000178     0.000007    -0.000252     0.000072   \n",
       "std       0.016059     0.016464     0.004793     0.011794     0.010250   \n",
       "min      -0.112019    -0.110645    -0.024921    -0.103782    -0.054910   \n",
       "25%      -0.008649    -0.008880    -0.002635    -0.005469    -0.005554   \n",
       "50%       0.000000     0.000000     0.000000    -0.000390     0.000000   \n",
       "75%       0.007562     0.007760     0.002658     0.003949     0.005375   \n",
       "max       0.109603     0.109134     0.027541     0.136158     0.066117   \n",
       "\n",
       "              MXWD          XAU          XAG  LMCADY_acu_5d  LMCADY_std_5d  \n",
       "count  5539.000000  5539.000000  5539.000000    5539.000000    5539.000000  \n",
       "mean     -0.000205    -0.000274    -0.000106      -0.000867       0.014218  \n",
       "std       0.009880     0.010722     0.019587       0.034782       0.008721  \n",
       "min      -0.085172    -0.097378    -0.123485      -0.185825       0.000805  \n",
       "25%      -0.004878    -0.005978    -0.009770      -0.021102       0.008616  \n",
       "50%      -0.000643    -0.000497    -0.000771      -0.001844       0.012148  \n",
       "75%       0.003807     0.004908     0.008074       0.017065       0.017520  \n",
       "max       0.105134     0.099792     0.226116       0.259832       0.091981  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./input/copper_returns_5d_final.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5539, 8)\n"
     ]
    }
   ],
   "source": [
    "features = df.drop(['Date', 'LMCADY_std_5d', 'LMCADY_acu_5d'], axis=1)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_features = scaler.fit_transform(df.drop(['Date','LMCADY_std_5d','LMCADY_acu_5d'], axis=1))\n",
    "# features = scaled_features\n",
    "\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearSecuencias(data, n_steps):\n",
    "    X, y = [], []\n",
    "    data = data.values  # Asegurarse de que 'data' es un array de NumPy\n",
    "    for i in range(n_steps, len(data)):\n",
    "        X.append(data[i-n_steps:i, :-2])  # las variables excepto los target\n",
    "        y.append(data[i, -2:])            # los target\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5514, 25, 6) (5514, 2)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 25  # ventana modificable\n",
    "X, y = crearSecuencias(features, n_steps)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.24125480e-03  1.04704023e-03 -7.67018217e-04  2.80768240e-03\n",
      "   6.12699272e-03  1.18171426e-03]\n",
      " [-7.32559450e-04 -1.81555969e-04  2.01496834e-03  3.06428091e-03\n",
      "  -5.82881005e-03  2.39912759e-03]\n",
      " [ 9.47386229e-03  9.32156546e-03 -4.02183281e-03  1.40423142e-03\n",
      "   7.49108445e-03  2.58536835e-03]\n",
      " [-2.51382604e-03 -2.12952297e-03 -5.96096529e-03 -3.22615725e-03\n",
      "  -1.95286967e-03 -6.74036817e-03]\n",
      " [ 5.43234767e-03  5.89306530e-03  4.15900958e-03 -8.82552224e-03\n",
      "   3.44083378e-03 -6.09207516e-03]\n",
      " [ 1.25327243e-02  1.29976857e-02 -2.31169332e-03 -5.61744594e-03\n",
      "   8.81608423e-04 -2.37935137e-03]\n",
      " [-1.87039278e-03 -1.95969112e-03 -1.44815601e-03 -6.27837698e-03\n",
      "  -4.90577206e-03 -5.00337015e-03]\n",
      " [-2.03373016e-02 -2.06556280e-02 -6.76786232e-04  6.52519303e-03\n",
      "  -1.12108641e-03  6.55272140e-03]\n",
      " [ 4.44444444e-03  5.71656278e-03 -5.51470588e-03  2.87934328e-03\n",
      "  -8.75065479e-04  3.42975474e-03]\n",
      " [-3.02453232e-02 -3.08780478e-02  1.65385738e-03  1.92824826e-03\n",
      "  -8.15826797e-03  5.28827551e-04]\n",
      " [-4.62053829e-04 -1.22653521e-04 -8.74125874e-04 -1.10776829e-02\n",
      "   1.16821478e-03 -8.94664243e-03]\n",
      " [-8.49416387e-03 -8.45595322e-03 -1.55536114e-03  1.12349891e-03\n",
      "  -2.99800506e-03  3.29097129e-03]\n",
      " [ 7.10997144e-03  6.97750867e-03  1.07097654e-03  6.57143582e-03\n",
      "   2.94069630e-03  2.29482692e-03]\n",
      " [-7.34911174e-03 -7.28252183e-03  5.34915386e-03 -1.01990166e-02\n",
      "  -4.33605108e-03 -9.30058080e-03]\n",
      " [-9.96852046e-03 -9.84176562e-03  4.15981426e-03 -5.11483400e-03\n",
      "  -5.82224675e-03 -5.92782159e-03]\n",
      " [ 6.00600601e-03  6.56608041e-03  2.89017341e-04  1.02980123e-02\n",
      "   3.68565268e-03  7.60501222e-03]\n",
      " [-4.56540825e-03 -4.71977587e-03  2.88933834e-04  1.19471053e-03\n",
      "  -4.49645076e-03 -7.82136013e-05]\n",
      " [-1.17598636e-03 -1.72290875e-03  2.88850376e-03 -7.94420176e-03\n",
      "  -5.31601377e-03 -7.54820290e-03]\n",
      " [-5.29816919e-03 -5.56448253e-03 -1.72811060e-03 -5.20184370e-03\n",
      "  -4.48815860e-04 -4.13776797e-03]\n",
      " [ 3.01828727e-03  2.45369401e-03 -1.44258511e-03  1.66082813e-03\n",
      "   3.10380682e-05  3.38991993e-03]\n",
      " [-9.44064196e-04 -1.64174204e-03  0.00000000e+00 -1.70336617e-03\n",
      "  -8.92316765e-03 -2.01130538e-03]\n",
      " [ 1.19891330e-02  1.35741195e-02  1.05942406e-03  3.80114133e-03\n",
      "  -4.07845839e-03  2.64762833e-03]\n",
      " [ 1.98424278e-03  2.89085546e-03  1.92418703e-04 -3.47822669e-04\n",
      "   1.05885103e-02 -1.01158727e-03]\n",
      " [-4.95078339e-03 -5.05912112e-03  4.80954213e-04 -2.06859405e-02\n",
      "   1.43130513e-03 -1.64385003e-02]\n",
      " [-4.91688129e-03 -3.84438006e-03  6.73012210e-04 -1.26259585e-03\n",
      "  -7.45079153e-03  4.27858967e-04]]\n",
      "[[-7.32559450e-04 -1.81555969e-04  2.01496834e-03  3.06428091e-03\n",
      "  -5.82881005e-03  2.39912759e-03]\n",
      " [ 9.47386229e-03  9.32156546e-03 -4.02183281e-03  1.40423142e-03\n",
      "   7.49108445e-03  2.58536835e-03]\n",
      " [-2.51382604e-03 -2.12952297e-03 -5.96096529e-03 -3.22615725e-03\n",
      "  -1.95286967e-03 -6.74036817e-03]\n",
      " [ 5.43234767e-03  5.89306530e-03  4.15900958e-03 -8.82552224e-03\n",
      "   3.44083378e-03 -6.09207516e-03]\n",
      " [ 1.25327243e-02  1.29976857e-02 -2.31169332e-03 -5.61744594e-03\n",
      "   8.81608423e-04 -2.37935137e-03]\n",
      " [-1.87039278e-03 -1.95969112e-03 -1.44815601e-03 -6.27837698e-03\n",
      "  -4.90577206e-03 -5.00337015e-03]\n",
      " [-2.03373016e-02 -2.06556280e-02 -6.76786232e-04  6.52519303e-03\n",
      "  -1.12108641e-03  6.55272140e-03]\n",
      " [ 4.44444444e-03  5.71656278e-03 -5.51470588e-03  2.87934328e-03\n",
      "  -8.75065479e-04  3.42975474e-03]\n",
      " [-3.02453232e-02 -3.08780478e-02  1.65385738e-03  1.92824826e-03\n",
      "  -8.15826797e-03  5.28827551e-04]\n",
      " [-4.62053829e-04 -1.22653521e-04 -8.74125874e-04 -1.10776829e-02\n",
      "   1.16821478e-03 -8.94664243e-03]\n",
      " [-8.49416387e-03 -8.45595322e-03 -1.55536114e-03  1.12349891e-03\n",
      "  -2.99800506e-03  3.29097129e-03]\n",
      " [ 7.10997144e-03  6.97750867e-03  1.07097654e-03  6.57143582e-03\n",
      "   2.94069630e-03  2.29482692e-03]\n",
      " [-7.34911174e-03 -7.28252183e-03  5.34915386e-03 -1.01990166e-02\n",
      "  -4.33605108e-03 -9.30058080e-03]\n",
      " [-9.96852046e-03 -9.84176562e-03  4.15981426e-03 -5.11483400e-03\n",
      "  -5.82224675e-03 -5.92782159e-03]\n",
      " [ 6.00600601e-03  6.56608041e-03  2.89017341e-04  1.02980123e-02\n",
      "   3.68565268e-03  7.60501222e-03]\n",
      " [-4.56540825e-03 -4.71977587e-03  2.88933834e-04  1.19471053e-03\n",
      "  -4.49645076e-03 -7.82136013e-05]\n",
      " [-1.17598636e-03 -1.72290875e-03  2.88850376e-03 -7.94420176e-03\n",
      "  -5.31601377e-03 -7.54820290e-03]\n",
      " [-5.29816919e-03 -5.56448253e-03 -1.72811060e-03 -5.20184370e-03\n",
      "  -4.48815860e-04 -4.13776797e-03]\n",
      " [ 3.01828727e-03  2.45369401e-03 -1.44258511e-03  1.66082813e-03\n",
      "   3.10380682e-05  3.38991993e-03]\n",
      " [-9.44064196e-04 -1.64174204e-03  0.00000000e+00 -1.70336617e-03\n",
      "  -8.92316765e-03 -2.01130538e-03]\n",
      " [ 1.19891330e-02  1.35741195e-02  1.05942406e-03  3.80114133e-03\n",
      "  -4.07845839e-03  2.64762833e-03]\n",
      " [ 1.98424278e-03  2.89085546e-03  1.92418703e-04 -3.47822669e-04\n",
      "   1.05885103e-02 -1.01158727e-03]\n",
      " [-4.95078339e-03 -5.05912112e-03  4.80954213e-04 -2.06859405e-02\n",
      "   1.43130513e-03 -1.64385003e-02]\n",
      " [-4.91688129e-03 -3.84438006e-03  6.73012210e-04 -1.26259585e-03\n",
      "  -7.45079153e-03  4.27858967e-04]\n",
      " [-7.70588235e-03 -8.36776872e-03  2.01767871e-03  6.04159172e-03\n",
      "   4.37213894e-03  3.18084012e-03]]\n"
     ]
    }
   ],
   "source": [
    "# verificar que haya secuencia\n",
    "print(X[0])\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00355659,  0.00080418],\n",
       "       [-0.00179456,  0.01726519],\n",
       "       [-0.00456399, -0.0211992 ],\n",
       "       ...,\n",
       "       [ 0.        , -0.00153139],\n",
       "       [-0.01480427, -0.01472393],\n",
       "       [ 0.00577951, -0.00788709]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0107347 , 0.01960124])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desviación estándar de los target\n",
    "np.std(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(n_steps, X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2)  # dos variables target\n",
    "])\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "huber_loss = Huber(delta=0.05)  # Puedes ajustar delta según sea necesario\n",
    "model.compile(optimizer=optimizer, loss=huber_loss, metrics=[rmse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 6ms/step - loss: 1.1665e-04 - rmse: 0.0154 - val_loss: 1.1755e-04 - val_rmse: 0.0155\n",
      "Epoch 2/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.1555e-04 - rmse: 0.0153 - val_loss: 1.2000e-04 - val_rmse: 0.0157\n",
      "Epoch 3/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1454e-04 - rmse: 0.0153 - val_loss: 1.1705e-04 - val_rmse: 0.0155\n",
      "Epoch 4/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1444e-04 - rmse: 0.0152 - val_loss: 1.1689e-04 - val_rmse: 0.0155\n",
      "Epoch 5/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1292e-04 - rmse: 0.0151 - val_loss: 1.1773e-04 - val_rmse: 0.0156\n",
      "Epoch 6/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1235e-04 - rmse: 0.0150 - val_loss: 1.1718e-04 - val_rmse: 0.0155\n",
      "Epoch 7/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1049e-04 - rmse: 0.0150 - val_loss: 1.1806e-04 - val_rmse: 0.0156\n",
      "Epoch 8/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0919e-04 - rmse: 0.0148 - val_loss: 1.1718e-04 - val_rmse: 0.0155\n",
      "Epoch 9/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0658e-04 - rmse: 0.0146 - val_loss: 1.1756e-04 - val_rmse: 0.0156\n",
      "Epoch 10/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0646e-04 - rmse: 0.0146 - val_loss: 1.2338e-04 - val_rmse: 0.0160\n",
      "Epoch 11/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0453e-04 - rmse: 0.0145 - val_loss: 1.1867e-04 - val_rmse: 0.0157\n",
      "Epoch 12/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0338e-04 - rmse: 0.0144 - val_loss: 1.2024e-04 - val_rmse: 0.0158\n",
      "Epoch 13/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0108e-04 - rmse: 0.0142 - val_loss: 1.2112e-04 - val_rmse: 0.0159\n",
      "Epoch 14/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.9034e-05 - rmse: 0.0140 - val_loss: 1.2347e-04 - val_rmse: 0.0161\n",
      "Epoch 15/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.8837e-05 - rmse: 0.0140 - val_loss: 1.2300e-04 - val_rmse: 0.0160\n",
      "Epoch 16/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.6991e-05 - rmse: 0.0139 - val_loss: 1.2713e-04 - val_rmse: 0.0163\n",
      "Epoch 17/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.4913e-05 - rmse: 0.0137 - val_loss: 1.2434e-04 - val_rmse: 0.0160\n",
      "Epoch 18/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.5029e-05 - rmse: 0.0137 - val_loss: 1.2437e-04 - val_rmse: 0.0161\n",
      "Epoch 19/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.4561e-05 - rmse: 0.0137 - val_loss: 1.2825e-04 - val_rmse: 0.0164\n",
      "Epoch 20/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.3816e-05 - rmse: 0.0136 - val_loss: 1.2262e-04 - val_rmse: 0.0160\n",
      "Epoch 21/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.0891e-05 - rmse: 0.0134 - val_loss: 1.2318e-04 - val_rmse: 0.0161\n",
      "Epoch 22/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.9448e-05 - rmse: 0.0133 - val_loss: 1.3197e-04 - val_rmse: 0.0166\n",
      "Epoch 23/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.8538e-05 - rmse: 0.0132 - val_loss: 1.2955e-04 - val_rmse: 0.0165\n",
      "Epoch 24/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.7272e-05 - rmse: 0.0131 - val_loss: 1.2665e-04 - val_rmse: 0.0163\n",
      "Epoch 25/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.5366e-05 - rmse: 0.0130 - val_loss: 1.2726e-04 - val_rmse: 0.0164\n",
      "Epoch 26/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.4701e-05 - rmse: 0.0129 - val_loss: 1.3054e-04 - val_rmse: 0.0166\n",
      "Epoch 27/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.5493e-05 - rmse: 0.0130 - val_loss: 1.2967e-04 - val_rmse: 0.0165\n",
      "Epoch 28/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.4694e-05 - rmse: 0.0130 - val_loss: 1.3065e-04 - val_rmse: 0.0166\n",
      "Epoch 29/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.3568e-05 - rmse: 0.0128 - val_loss: 1.3205e-04 - val_rmse: 0.0167\n",
      "Epoch 30/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.1988e-05 - rmse: 0.0127 - val_loss: 1.3331e-04 - val_rmse: 0.0168\n",
      "Epoch 31/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.1626e-05 - rmse: 0.0127 - val_loss: 1.2961e-04 - val_rmse: 0.0166\n",
      "Epoch 32/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.8943e-05 - rmse: 0.0125 - val_loss: 1.3190e-04 - val_rmse: 0.0167\n",
      "Epoch 33/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.8380e-05 - rmse: 0.0124 - val_loss: 1.3824e-04 - val_rmse: 0.0171\n",
      "Epoch 34/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.8872e-05 - rmse: 0.0125 - val_loss: 1.3632e-04 - val_rmse: 0.0169\n",
      "Epoch 35/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.7302e-05 - rmse: 0.0123 - val_loss: 1.4002e-04 - val_rmse: 0.0172\n",
      "Epoch 36/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.5879e-05 - rmse: 0.0122 - val_loss: 1.4246e-04 - val_rmse: 0.0174\n",
      "Epoch 37/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.6518e-05 - rmse: 0.0123 - val_loss: 1.3999e-04 - val_rmse: 0.0172\n",
      "Epoch 38/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.4589e-05 - rmse: 0.0121 - val_loss: 1.3911e-04 - val_rmse: 0.0172\n",
      "Epoch 39/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.4089e-05 - rmse: 0.0121 - val_loss: 1.4222e-04 - val_rmse: 0.0173\n",
      "Epoch 40/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.3320e-05 - rmse: 0.0120 - val_loss: 1.4093e-04 - val_rmse: 0.0173\n",
      "Epoch 41/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 7.2204e-05 - rmse: 0.0119 - val_loss: 1.3775e-04 - val_rmse: 0.0170\n",
      "Epoch 42/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.1321e-05 - rmse: 0.0118 - val_loss: 1.4199e-04 - val_rmse: 0.0172\n",
      "Epoch 43/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.0086e-05 - rmse: 0.0117 - val_loss: 1.3454e-04 - val_rmse: 0.0168\n",
      "Epoch 44/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.1057e-05 - rmse: 0.0118 - val_loss: 1.4670e-04 - val_rmse: 0.0176\n",
      "Epoch 45/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.8637e-05 - rmse: 0.0116 - val_loss: 1.4161e-04 - val_rmse: 0.0171\n",
      "Epoch 46/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.6488e-05 - rmse: 0.0114 - val_loss: 1.4464e-04 - val_rmse: 0.0175\n",
      "Epoch 47/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.7020e-05 - rmse: 0.0115 - val_loss: 1.4478e-04 - val_rmse: 0.0174\n",
      "Epoch 48/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.6561e-05 - rmse: 0.0114 - val_loss: 1.4432e-04 - val_rmse: 0.0174\n",
      "Epoch 49/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.5158e-05 - rmse: 0.0113 - val_loss: 1.4735e-04 - val_rmse: 0.0176\n",
      "Epoch 50/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.4746e-05 - rmse: 0.0113 - val_loss: 1.4557e-04 - val_rmse: 0.0175\n",
      "Epoch 51/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.3226e-05 - rmse: 0.0111 - val_loss: 1.4449e-04 - val_rmse: 0.0174\n",
      "Epoch 52/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.2543e-05 - rmse: 0.0110 - val_loss: 1.4734e-04 - val_rmse: 0.0176\n",
      "Epoch 53/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1286e-05 - rmse: 0.0110 - val_loss: 1.4477e-04 - val_rmse: 0.0174\n",
      "Epoch 54/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1581e-05 - rmse: 0.0109 - val_loss: 1.5288e-04 - val_rmse: 0.0179\n",
      "Epoch 55/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.9880e-05 - rmse: 0.0108 - val_loss: 1.4847e-04 - val_rmse: 0.0177\n",
      "Epoch 56/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.7987e-05 - rmse: 0.0107 - val_loss: 1.5732e-04 - val_rmse: 0.0182\n",
      "Epoch 57/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.7878e-05 - rmse: 0.0106 - val_loss: 1.4546e-04 - val_rmse: 0.0174\n",
      "Epoch 58/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.8021e-05 - rmse: 0.0106 - val_loss: 1.4532e-04 - val_rmse: 0.0174\n",
      "Epoch 59/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6651e-05 - rmse: 0.0105 - val_loss: 1.5173e-04 - val_rmse: 0.0178\n",
      "Epoch 60/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6032e-05 - rmse: 0.0105 - val_loss: 1.5052e-04 - val_rmse: 0.0177\n",
      "Epoch 61/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.7266e-05 - rmse: 0.0106 - val_loss: 1.5026e-04 - val_rmse: 0.0177\n",
      "Epoch 62/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5098e-05 - rmse: 0.0104 - val_loss: 1.6120e-04 - val_rmse: 0.0183\n",
      "Epoch 63/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5067e-05 - rmse: 0.0104 - val_loss: 1.5417e-04 - val_rmse: 0.0180\n",
      "Epoch 64/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2703e-05 - rmse: 0.0101 - val_loss: 1.5571e-04 - val_rmse: 0.0181\n",
      "Epoch 65/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.1524e-05 - rmse: 0.0100 - val_loss: 1.5592e-04 - val_rmse: 0.0180\n",
      "Epoch 66/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.1010e-05 - rmse: 0.0100 - val_loss: 1.5776e-04 - val_rmse: 0.0181\n",
      "Epoch 67/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.1382e-05 - rmse: 0.0100 - val_loss: 1.5605e-04 - val_rmse: 0.0181\n",
      "Epoch 68/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2572e-05 - rmse: 0.0101 - val_loss: 1.5730e-04 - val_rmse: 0.0181\n",
      "Epoch 69/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.0008e-05 - rmse: 0.0098 - val_loss: 1.5601e-04 - val_rmse: 0.0181\n",
      "Epoch 70/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.9495e-05 - rmse: 0.0098 - val_loss: 1.6093e-04 - val_rmse: 0.0184\n",
      "Epoch 71/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8569e-05 - rmse: 0.0097 - val_loss: 1.5649e-04 - val_rmse: 0.0181\n",
      "Epoch 72/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7046e-05 - rmse: 0.0096 - val_loss: 1.5587e-04 - val_rmse: 0.0180\n",
      "Epoch 73/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8329e-05 - rmse: 0.0097 - val_loss: 1.6428e-04 - val_rmse: 0.0185\n",
      "Epoch 74/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.6876e-05 - rmse: 0.0096 - val_loss: 1.6159e-04 - val_rmse: 0.0184\n",
      "Epoch 75/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.5815e-05 - rmse: 0.0095 - val_loss: 1.6160e-04 - val_rmse: 0.0184\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='rmse',  # Monitorea la pérdida de validación\n",
    "    patience=15,         # Número de epochs sin mejora después del cual el entrenamiento será detenido\n",
    "    restore_best_weights=True  # Restaura los pesos del modelo desde la epoch con la mejor pérdida de validación\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=75, verbose=1, validation_split=0.15, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 1.6953e-04 - rmse: 0.0186\n",
      "Loss on test data: [0.00016953295562416315, 0.018628088757395744]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Loss on test data: {loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
