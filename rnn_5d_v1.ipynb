{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMCADS03</th>\n",
       "      <th>LMCADY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>SPX</th>\n",
       "      <th>BCOM</th>\n",
       "      <th>MXWD</th>\n",
       "      <th>XAU</th>\n",
       "      <th>XAG</th>\n",
       "      <th>LMCADY_acu_5d</th>\n",
       "      <th>LMCADY_std_5d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "      <td>5539.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>0.014218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.008721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.112019</td>\n",
       "      <td>-0.110645</td>\n",
       "      <td>-0.024921</td>\n",
       "      <td>-0.103782</td>\n",
       "      <td>-0.054910</td>\n",
       "      <td>-0.085172</td>\n",
       "      <td>-0.097378</td>\n",
       "      <td>-0.123485</td>\n",
       "      <td>-0.185825</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.008649</td>\n",
       "      <td>-0.008880</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.005469</td>\n",
       "      <td>-0.005554</td>\n",
       "      <td>-0.004878</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.008616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.012148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>0.027541</td>\n",
       "      <td>0.136158</td>\n",
       "      <td>0.066117</td>\n",
       "      <td>0.105134</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.226116</td>\n",
       "      <td>0.259832</td>\n",
       "      <td>0.091981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LMCADS03       LMCADY          DXY          SPX         BCOM  \\\n",
       "count  5539.000000  5539.000000  5539.000000  5539.000000  5539.000000   \n",
       "mean     -0.000185    -0.000178     0.000007    -0.000252     0.000072   \n",
       "std       0.016059     0.016464     0.004793     0.011794     0.010250   \n",
       "min      -0.112019    -0.110645    -0.024921    -0.103782    -0.054910   \n",
       "25%      -0.008649    -0.008880    -0.002635    -0.005469    -0.005554   \n",
       "50%       0.000000     0.000000     0.000000    -0.000390     0.000000   \n",
       "75%       0.007562     0.007760     0.002658     0.003949     0.005375   \n",
       "max       0.109603     0.109134     0.027541     0.136158     0.066117   \n",
       "\n",
       "              MXWD          XAU          XAG  LMCADY_acu_5d  LMCADY_std_5d  \n",
       "count  5539.000000  5539.000000  5539.000000    5539.000000    5539.000000  \n",
       "mean     -0.000205    -0.000274    -0.000106      -0.000867       0.014218  \n",
       "std       0.009880     0.010722     0.019587       0.034782       0.008721  \n",
       "min      -0.085172    -0.097378    -0.123485      -0.185825       0.000805  \n",
       "25%      -0.004878    -0.005978    -0.009770      -0.021102       0.008616  \n",
       "50%      -0.000643    -0.000497    -0.000771      -0.001844       0.012148  \n",
       "75%       0.003807     0.004908     0.008074       0.017065       0.017520  \n",
       "max       0.105134     0.099792     0.226116       0.259832       0.091981  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./input/copper_returns_5d_final.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5539, 8) (5539,)\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(columns=['Date','LMCADY_std_5d','LMCADY_acu_5d'])\n",
    "targets = data['LMCADY_acu_5d']\n",
    "print(features.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMCADS03</th>\n",
       "      <th>LMCADY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>SPX</th>\n",
       "      <th>BCOM</th>\n",
       "      <th>MXWD</th>\n",
       "      <th>XAU</th>\n",
       "      <th>XAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>0.009327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>-0.005829</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>-0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>-0.004022</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002514</td>\n",
       "      <td>-0.002130</td>\n",
       "      <td>-0.005961</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.006740</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.033895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>-0.008826</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>-0.006092</td>\n",
       "      <td>-0.013172</td>\n",
       "      <td>-0.026096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>-0.009774</td>\n",
       "      <td>-0.009724</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>-0.018041</td>\n",
       "      <td>-0.010309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>-0.005850</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.020312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>-0.010746</td>\n",
       "      <td>-0.010210</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>-0.021980</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>-0.018378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>-0.013035</td>\n",
       "      <td>-0.013388</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.014186</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.014804</td>\n",
       "      <td>-0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>-0.018868</td>\n",
       "      <td>-0.019639</td>\n",
       "      <td>-0.010682</td>\n",
       "      <td>-0.032133</td>\n",
       "      <td>-0.025019</td>\n",
       "      <td>-0.022941</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>-0.007887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LMCADS03    LMCADY       DXY       SPX      BCOM      MXWD       XAU  \\\n",
       "0     0.001241  0.001047 -0.000767  0.002808  0.006127  0.001182 -0.003199   \n",
       "1    -0.000733 -0.000182  0.002015  0.003064 -0.005829  0.002399 -0.002942   \n",
       "2     0.009474  0.009322 -0.004022  0.001404  0.007491  0.002585  0.007338   \n",
       "3    -0.002514 -0.002130 -0.005961 -0.003226 -0.001953 -0.006740  0.002320   \n",
       "4     0.005432  0.005893  0.004159 -0.008826  0.003441 -0.006092 -0.013172   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534 -0.009774 -0.009724  0.006872  0.014287 -0.004085  0.014765 -0.018041   \n",
       "5535  0.004627  0.004489 -0.005850  0.006588  0.002701  0.008892  0.011519   \n",
       "5536 -0.010746 -0.010210  0.004903 -0.021980  0.016248 -0.018378  0.000000   \n",
       "5537 -0.013035 -0.013388  0.004977  0.000484 -0.014186 -0.003775 -0.014804   \n",
       "5538 -0.018868 -0.019639 -0.010682 -0.032133 -0.025019 -0.022941  0.005780   \n",
       "\n",
       "           XAG  \n",
       "0     0.009327  \n",
       "1    -0.000409  \n",
       "2     0.002853  \n",
       "3     0.033895  \n",
       "4    -0.026096  \n",
       "...        ...  \n",
       "5534 -0.010309  \n",
       "5535  0.020312  \n",
       "5536 -0.001531  \n",
       "5537 -0.014724  \n",
       "5538 -0.007887  \n",
       "\n",
       "[5539 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = StandardScaler()\n",
    "# features_normalized = scaler.fit_transform(features)\n",
    "# print(features_normalized.shape)\n",
    "# features = features_normalized\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                11800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,851\n",
      "Trainable params: 11,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[rmse])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "139/139 [==============================] - 5s 6ms/step - loss: 0.0011 - rmse: 0.0324 - val_loss: 9.6807e-04 - val_rmse: 0.0307\n",
      "Epoch 2/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0010 - rmse: 0.0311 - val_loss: 9.3389e-04 - val_rmse: 0.0301\n",
      "Epoch 3/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 0.0010 - rmse: 0.0311 - val_loss: 9.0110e-04 - val_rmse: 0.0295\n",
      "Epoch 4/50\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 0.0010 - rmse: 0.0311 - val_loss: 9.0176e-04 - val_rmse: 0.0295\n",
      "Epoch 5/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9951e-04 - rmse: 0.0311 - val_loss: 9.1664e-04 - val_rmse: 0.0298\n",
      "Epoch 6/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 0.0010 - rmse: 0.0312 - val_loss: 9.1801e-04 - val_rmse: 0.0298\n",
      "Epoch 7/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9644e-04 - rmse: 0.0311 - val_loss: 9.0665e-04 - val_rmse: 0.0296\n",
      "Epoch 8/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9327e-04 - rmse: 0.0309 - val_loss: 8.9954e-04 - val_rmse: 0.0295\n",
      "Epoch 9/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9107e-04 - rmse: 0.0309 - val_loss: 9.0561e-04 - val_rmse: 0.0296\n",
      "Epoch 10/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9360e-04 - rmse: 0.0310 - val_loss: 8.9669e-04 - val_rmse: 0.0295\n",
      "Epoch 11/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.8950e-04 - rmse: 0.0310 - val_loss: 9.0030e-04 - val_rmse: 0.0295\n",
      "Epoch 12/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9114e-04 - rmse: 0.0309 - val_loss: 9.0214e-04 - val_rmse: 0.0296\n",
      "Epoch 13/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9752e-04 - rmse: 0.0310 - val_loss: 9.0971e-04 - val_rmse: 0.0297\n",
      "Epoch 14/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9630e-04 - rmse: 0.0309 - val_loss: 8.9953e-04 - val_rmse: 0.0295\n",
      "Epoch 15/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9383e-04 - rmse: 0.0310 - val_loss: 8.9457e-04 - val_rmse: 0.0294\n",
      "Epoch 16/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9475e-04 - rmse: 0.0309 - val_loss: 8.9891e-04 - val_rmse: 0.0295\n",
      "Epoch 17/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9161e-04 - rmse: 0.0309 - val_loss: 8.9390e-04 - val_rmse: 0.0294\n",
      "Epoch 18/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9485e-04 - rmse: 0.0308 - val_loss: 9.1681e-04 - val_rmse: 0.0298\n",
      "Epoch 19/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.9317e-04 - rmse: 0.0309 - val_loss: 9.0034e-04 - val_rmse: 0.0295\n",
      "Epoch 20/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9421e-04 - rmse: 0.0310 - val_loss: 8.9648e-04 - val_rmse: 0.0295\n",
      "Epoch 21/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 0.0010 - rmse: 0.0312 - val_loss: 9.0170e-04 - val_rmse: 0.0296\n",
      "Epoch 22/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9106e-04 - rmse: 0.0309 - val_loss: 9.1604e-04 - val_rmse: 0.0298\n",
      "Epoch 23/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9312e-04 - rmse: 0.0309 - val_loss: 9.7501e-04 - val_rmse: 0.0308\n",
      "Epoch 24/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.8862e-04 - rmse: 0.0309 - val_loss: 9.1920e-04 - val_rmse: 0.0299\n",
      "Epoch 25/50\n",
      "139/139 [==============================] - 0s 4ms/step - loss: 9.8961e-04 - rmse: 0.0309 - val_loss: 9.1558e-04 - val_rmse: 0.0298\n",
      "Epoch 26/50\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 9.8640e-04 - rmse: 0.0308 - val_loss: 8.9554e-04 - val_rmse: 0.0294\n",
      "Epoch 27/50\n",
      "139/139 [==============================] - 0s 4ms/step - loss: 9.8712e-04 - rmse: 0.0309 - val_loss: 8.9483e-04 - val_rmse: 0.0294\n",
      "Epoch 28/50\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 9.8821e-04 - rmse: 0.0309 - val_loss: 9.0200e-04 - val_rmse: 0.0296\n",
      "Epoch 29/50\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 9.9009e-04 - rmse: 0.0308 - val_loss: 9.0833e-04 - val_rmse: 0.0297\n",
      "Epoch 30/50\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 9.9787e-04 - rmse: 0.0310 - val_loss: 8.9786e-04 - val_rmse: 0.0295\n",
      "Epoch 31/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.8610e-04 - rmse: 0.0309 - val_loss: 8.9512e-04 - val_rmse: 0.0294\n",
      "Epoch 32/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.8879e-04 - rmse: 0.0309 - val_loss: 9.3869e-04 - val_rmse: 0.0302\n",
      "Epoch 33/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.9084e-04 - rmse: 0.0309 - val_loss: 9.1985e-04 - val_rmse: 0.0299\n",
      "Epoch 34/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.8887e-04 - rmse: 0.0308 - val_loss: 8.9662e-04 - val_rmse: 0.0295\n",
      "Epoch 35/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.9469e-04 - rmse: 0.0309 - val_loss: 9.0749e-04 - val_rmse: 0.0296\n",
      "Epoch 36/50\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 9.8278e-04 - rmse: 0.0307 - val_loss: 8.9549e-04 - val_rmse: 0.0294\n",
      "Epoch 37/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.9093e-04 - rmse: 0.0309 - val_loss: 8.9607e-04 - val_rmse: 0.0294\n",
      "Epoch 38/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.9268e-04 - rmse: 0.0309 - val_loss: 9.0692e-04 - val_rmse: 0.0296\n",
      "Epoch 39/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.9247e-04 - rmse: 0.0309 - val_loss: 8.9649e-04 - val_rmse: 0.0294\n",
      "Epoch 40/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.8471e-04 - rmse: 0.0309 - val_loss: 9.0086e-04 - val_rmse: 0.0295\n",
      "Epoch 41/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.8729e-04 - rmse: 0.0308 - val_loss: 8.9795e-04 - val_rmse: 0.0295\n",
      "Epoch 42/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.8161e-04 - rmse: 0.0308 - val_loss: 8.9704e-04 - val_rmse: 0.0295\n",
      "Epoch 43/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.8419e-04 - rmse: 0.0308 - val_loss: 9.0389e-04 - val_rmse: 0.0296\n",
      "Epoch 44/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.8636e-04 - rmse: 0.0308 - val_loss: 8.9844e-04 - val_rmse: 0.0295\n",
      "Epoch 45/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.8864e-04 - rmse: 0.0308 - val_loss: 9.1382e-04 - val_rmse: 0.0298\n",
      "Epoch 46/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.8556e-04 - rmse: 0.0308 - val_loss: 9.0623e-04 - val_rmse: 0.0296\n",
      "Epoch 47/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.9280e-04 - rmse: 0.0310 - val_loss: 8.9897e-04 - val_rmse: 0.0295\n",
      "Epoch 48/50\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 9.8267e-04 - rmse: 0.0308 - val_loss: 9.0676e-04 - val_rmse: 0.0296\n",
      "Epoch 49/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.9202e-04 - rmse: 0.0309 - val_loss: 8.9744e-04 - val_rmse: 0.0295\n",
      "Epoch 50/50\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 9.8604e-04 - rmse: 0.0308 - val_loss: 9.3229e-04 - val_rmse: 0.0301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2538a96e2e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 5ms/step - loss: 9.3229e-04 - rmse: 0.0301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0009322912083007395, 0.030073203146457672]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
