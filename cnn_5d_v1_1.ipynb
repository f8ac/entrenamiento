{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import Huber\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./input/copper_returns_5d_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5539, 8)\n"
     ]
    }
   ],
   "source": [
    "features = df.drop(['Date', 'LMCADY_std_5d', 'LMCADY_acu_5d'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.drop(['Date','LMCADY_std_5d','LMCADY_acu_5d'], axis=1))\n",
    "features = scaled_features\n",
    "\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearSecuencias(data, n_steps):\n",
    "    X, y = [], []\n",
    "    print(data)\n",
    "    try:\n",
    "        data = data.values  # Asegurarse de que 'data' es un array de NumPy\n",
    "    except:\n",
    "        pass\n",
    "    for i in range(n_steps, len(data)):\n",
    "        X.append(data[i-n_steps:i, :-2])  # las variables excepto los target\n",
    "        y.append(data[i, -2:])            # los target\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.88174336e-02  7.44158059e-02 -1.61553556e-01 ...  1.40393504e-01\n",
      "  -2.72839869e-01  4.81635337e-01]\n",
      " [-3.41047918e-02 -2.12838525e-04  4.18921718e-01 ...  2.63621263e-01\n",
      "  -2.48888913e-01 -1.54865105e-02]\n",
      " [ 6.01515341e-01  5.77035466e-01 -8.40686743e-01 ...  2.82472734e-01\n",
      "   7.09955572e-01  1.51088802e-01]\n",
      " ...\n",
      " [-6.57712049e-01 -6.09357555e-01  1.02160791e+00 ... -1.83950901e+00\n",
      "   2.55342740e-02 -7.27844599e-02]\n",
      " [-8.00281396e-01 -8.02392606e-01  1.03697816e+00 ... -3.61342573e-01\n",
      "  -1.35527210e+00 -7.46369564e-01]\n",
      " [-1.16351169e+00 -1.18211667e+00 -2.23029805e+00 ... -2.30137329e+00\n",
      "   5.64594036e-01 -3.97293980e-01]]\n",
      "(5514, 25, 6) (5514, 2)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 25  # ventana modificable\n",
    "X, y = crearSecuencias(features, n_steps)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.88174336e-02  7.44158059e-02 -1.61553556e-01  2.59411252e-01\n",
      "   5.90748707e-01  1.40393504e-01]\n",
      " [-3.41047918e-02 -2.12838525e-04  4.18921718e-01  2.81169283e-01\n",
      "  -5.75793243e-01  2.63621263e-01]\n",
      " [ 6.01515341e-01  5.77035466e-01 -8.40686743e-01  1.40406932e-01\n",
      "   7.23844766e-01  2.82472734e-01]\n",
      " [-1.45035825e-01 -1.18538239e-01 -1.24529634e+00 -2.52222565e-01\n",
      "  -1.97613112e-01 -6.61487364e-01]\n",
      " [ 3.49823992e-01  3.68778009e-01  8.66286542e-01 -7.27015508e-01\n",
      "   3.28656972e-01 -5.95866517e-01]\n",
      " [ 7.92010537e-01  8.00334113e-01 -4.83857667e-01 -4.54989665e-01\n",
      "   7.89502991e-02 -2.20061013e-01]\n",
      " [-1.04965059e-01 -1.08222140e-01 -3.03676332e-01 -5.11032697e-01\n",
      "  -4.85731323e-01 -4.85666739e-01]\n",
      " [-1.25501934e+00 -1.24386983e+00 -1.42726206e-01  5.74634106e-01\n",
      "  -1.16455026e-01  6.84052058e-01]\n",
      " [ 2.88300845e-01  3.58056712e-01 -1.15218210e+00  2.65487670e-01\n",
      "  -9.24504706e-02  3.67942343e-01]\n",
      " [-1.87205616e+00 -1.86481049e+00  3.43574128e-01  1.84840452e-01\n",
      "  -8.03081233e-01  7.43076787e-02]\n",
      " [-1.72586509e-02  3.36507409e-03 -1.83902100e-01 -9.17985376e-01\n",
      "   1.06914824e-01 -8.84808586e-01]\n",
      " [-5.17470281e-01 -5.02824725e-01 -3.26045211e-01  1.16602480e-01\n",
      "  -2.99588220e-01  3.53894548e-01]\n",
      " [ 4.54300514e-01  4.34650375e-01  2.21953153e-01  5.78555220e-01\n",
      "   2.79857961e-01  2.53063848e-01]\n",
      " [-4.46160452e-01 -4.31546957e-01  1.11461604e+00 -8.43479680e-01\n",
      "  -4.30142968e-01 -9.20634571e-01]\n",
      " [-6.09288036e-01 -5.87003157e-01  8.66454444e-01 -4.12371153e-01\n",
      "  -5.75152853e-01 -5.79240612e-01]\n",
      " [ 3.85549420e-01  4.09658980e-01  5.87934934e-02  8.94546801e-01\n",
      "   3.52544244e-01  7.90565956e-01]\n",
      " [-2.72801166e-01 -2.75878026e-01  5.87760693e-02  1.22640803e-01\n",
      "  -4.45793356e-01  1.28623843e-02]\n",
      " [-6.17198637e-02 -9.38392626e-02  6.01189210e-01 -6.52284759e-01\n",
      "  -5.25759097e-01 -7.43257180e-01]\n",
      " [-3.18434946e-01 -3.27188060e-01 -3.62090243e-01 -4.19749059e-01\n",
      "  -5.08607865e-02 -3.98049647e-01]\n",
      " [ 1.99484781e-01  1.59860206e-01 -3.02513936e-01  1.62164811e-01\n",
      "  -4.04086582e-03  3.63910226e-01]\n",
      " [-4.72765653e-02 -8.89089516e-02 -1.51140634e-03 -1.23098913e-01\n",
      "  -8.77713407e-01 -1.82807041e-01]\n",
      " [ 7.58157576e-01  8.35348444e-01  2.19542671e-01  3.43650677e-01\n",
      "  -4.05009341e-01  2.88774749e-01]\n",
      " [ 1.35088118e-01  1.86414713e-01  3.86377092e-02 -8.15686378e-03\n",
      "   1.02606430e+00 -8.16146042e-02]\n",
      " [-2.96800978e-01 -2.96490881e-01  9.88420725e-02 -1.73270864e+00\n",
      "   1.32584863e-01 -1.64314171e+00]\n",
      " [-2.94689674e-01 -2.22703839e-01  1.38915925e-01 -8.57242041e-02\n",
      "  -7.34051912e-01  6.40875407e-02]]\n",
      "[[-3.41047918e-02 -2.12838525e-04  4.18921718e-01  2.81169283e-01\n",
      "  -5.75793243e-01  2.63621263e-01]\n",
      " [ 6.01515341e-01  5.77035466e-01 -8.40686743e-01  1.40406932e-01\n",
      "   7.23844766e-01  2.82472734e-01]\n",
      " [-1.45035825e-01 -1.18538239e-01 -1.24529634e+00 -2.52222565e-01\n",
      "  -1.97613112e-01 -6.61487364e-01]\n",
      " [ 3.49823992e-01  3.68778009e-01  8.66286542e-01 -7.27015508e-01\n",
      "   3.28656972e-01 -5.95866517e-01]\n",
      " [ 7.92010537e-01  8.00334113e-01 -4.83857667e-01 -4.54989665e-01\n",
      "   7.89502991e-02 -2.20061013e-01]\n",
      " [-1.04965059e-01 -1.08222140e-01 -3.03676332e-01 -5.11032697e-01\n",
      "  -4.85731323e-01 -4.85666739e-01]\n",
      " [-1.25501934e+00 -1.24386983e+00 -1.42726206e-01  5.74634106e-01\n",
      "  -1.16455026e-01  6.84052058e-01]\n",
      " [ 2.88300845e-01  3.58056712e-01 -1.15218210e+00  2.65487670e-01\n",
      "  -9.24504706e-02  3.67942343e-01]\n",
      " [-1.87205616e+00 -1.86481049e+00  3.43574128e-01  1.84840452e-01\n",
      "  -8.03081233e-01  7.43076787e-02]\n",
      " [-1.72586509e-02  3.36507409e-03 -1.83902100e-01 -9.17985376e-01\n",
      "   1.06914824e-01 -8.84808586e-01]\n",
      " [-5.17470281e-01 -5.02824725e-01 -3.26045211e-01  1.16602480e-01\n",
      "  -2.99588220e-01  3.53894548e-01]\n",
      " [ 4.54300514e-01  4.34650375e-01  2.21953153e-01  5.78555220e-01\n",
      "   2.79857961e-01  2.53063848e-01]\n",
      " [-4.46160452e-01 -4.31546957e-01  1.11461604e+00 -8.43479680e-01\n",
      "  -4.30142968e-01 -9.20634571e-01]\n",
      " [-6.09288036e-01 -5.87003157e-01  8.66454444e-01 -4.12371153e-01\n",
      "  -5.75152853e-01 -5.79240612e-01]\n",
      " [ 3.85549420e-01  4.09658980e-01  5.87934934e-02  8.94546801e-01\n",
      "   3.52544244e-01  7.90565956e-01]\n",
      " [-2.72801166e-01 -2.75878026e-01  5.87760693e-02  1.22640803e-01\n",
      "  -4.45793356e-01  1.28623843e-02]\n",
      " [-6.17198637e-02 -9.38392626e-02  6.01189210e-01 -6.52284759e-01\n",
      "  -5.25759097e-01 -7.43257180e-01]\n",
      " [-3.18434946e-01 -3.27188060e-01 -3.62090243e-01 -4.19749059e-01\n",
      "  -5.08607865e-02 -3.98049647e-01]\n",
      " [ 1.99484781e-01  1.59860206e-01 -3.02513936e-01  1.62164811e-01\n",
      "  -4.04086582e-03  3.63910226e-01]\n",
      " [-4.72765653e-02 -8.89089516e-02 -1.51140634e-03 -1.23098913e-01\n",
      "  -8.77713407e-01 -1.82807041e-01]\n",
      " [ 7.58157576e-01  8.35348444e-01  2.19542671e-01  3.43650677e-01\n",
      "  -4.05009341e-01  2.88774749e-01]\n",
      " [ 1.35088118e-01  1.86414713e-01  3.86377092e-02 -8.15686378e-03\n",
      "   1.02606430e+00 -8.16146042e-02]\n",
      " [-2.96800978e-01 -2.96490881e-01  9.88420725e-02 -1.73270864e+00\n",
      "   1.32584863e-01 -1.64314171e+00]\n",
      " [-2.94689674e-01 -2.22703839e-01  1.38915925e-01 -8.57242041e-02\n",
      "  -7.34051912e-01  6.40875407e-02]\n",
      " [-4.68378874e-01 -4.97468132e-01  4.19487250e-01  5.33627582e-01\n",
      "   4.19525528e-01  3.42746964e-01]]\n"
     ]
    }
   ],
   "source": [
    "# verificar que haya secuencia\n",
    "print(X[0])\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30619194,  0.04646557],\n",
       "       [-0.1418456 ,  0.88693276],\n",
       "       [-0.40015258, -1.07698423],\n",
       "       ...,\n",
       "       [ 0.02553427, -0.07278446],\n",
       "       [-1.3552721 , -0.74636956],\n",
       "       [ 0.56459404, -0.39729398]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00123389, 1.00080109])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desviación estándar de los target\n",
    "np.std(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(n_steps, X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2)  # dos variables target\n",
    "])\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "huber_loss = Huber(delta=0.05)  # Puedes ajustar delta según sea necesario\n",
    "model.compile(optimizer=optimizer, loss=huber_loss, metrics=[rmse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0336 - rmse: 0.9840 - val_loss: 0.0337 - val_rmse: 0.9865\n",
      "Epoch 2/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0331 - rmse: 0.9648 - val_loss: 0.0337 - val_rmse: 0.9880\n",
      "Epoch 3/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0330 - rmse: 0.9713 - val_loss: 0.0337 - val_rmse: 0.9878\n",
      "Epoch 4/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0329 - rmse: 0.9738 - val_loss: 0.0338 - val_rmse: 0.9877\n",
      "Epoch 5/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0328 - rmse: 0.9649 - val_loss: 0.0339 - val_rmse: 0.9896\n",
      "Epoch 6/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0326 - rmse: 0.9625 - val_loss: 0.0339 - val_rmse: 0.9884\n",
      "Epoch 7/75\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0324 - rmse: 0.9630 - val_loss: 0.0341 - val_rmse: 0.9950\n",
      "Epoch 8/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0323 - rmse: 0.9585 - val_loss: 0.0343 - val_rmse: 0.9977\n",
      "Epoch 9/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0320 - rmse: 0.9486 - val_loss: 0.0342 - val_rmse: 0.9930\n",
      "Epoch 10/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0320 - rmse: 0.9476 - val_loss: 0.0343 - val_rmse: 0.9945\n",
      "Epoch 11/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0316 - rmse: 0.9440 - val_loss: 0.0344 - val_rmse: 0.9978\n",
      "Epoch 12/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0315 - rmse: 0.9413 - val_loss: 0.0349 - val_rmse: 1.0089\n",
      "Epoch 13/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0312 - rmse: 0.9342 - val_loss: 0.0346 - val_rmse: 1.0018\n",
      "Epoch 14/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0310 - rmse: 0.9301 - val_loss: 0.0349 - val_rmse: 1.0069\n",
      "Epoch 15/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0312 - rmse: 0.9296 - val_loss: 0.0350 - val_rmse: 1.0086\n",
      "Epoch 16/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0307 - rmse: 0.9233 - val_loss: 0.0349 - val_rmse: 1.0048\n",
      "Epoch 17/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0308 - rmse: 0.9246 - val_loss: 0.0350 - val_rmse: 1.0057\n",
      "Epoch 18/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0304 - rmse: 0.9175 - val_loss: 0.0356 - val_rmse: 1.0233\n",
      "Epoch 19/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0302 - rmse: 0.9085 - val_loss: 0.0353 - val_rmse: 1.0135\n",
      "Epoch 20/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0300 - rmse: 0.9093 - val_loss: 0.0353 - val_rmse: 1.0116\n",
      "Epoch 21/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0298 - rmse: 0.9000 - val_loss: 0.0355 - val_rmse: 1.0182\n",
      "Epoch 22/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0297 - rmse: 0.8985 - val_loss: 0.0353 - val_rmse: 1.0094\n",
      "Epoch 23/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0295 - rmse: 0.8997 - val_loss: 0.0364 - val_rmse: 1.0372\n",
      "Epoch 24/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0294 - rmse: 0.8904 - val_loss: 0.0359 - val_rmse: 1.0268\n",
      "Epoch 25/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0291 - rmse: 0.8844 - val_loss: 0.0363 - val_rmse: 1.0333\n",
      "Epoch 26/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0288 - rmse: 0.8828 - val_loss: 0.0359 - val_rmse: 1.0242\n",
      "Epoch 27/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0289 - rmse: 0.8782 - val_loss: 0.0363 - val_rmse: 1.0364\n",
      "Epoch 28/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0287 - rmse: 0.8758 - val_loss: 0.0360 - val_rmse: 1.0286\n",
      "Epoch 29/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0284 - rmse: 0.8705 - val_loss: 0.0361 - val_rmse: 1.0308\n",
      "Epoch 30/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0282 - rmse: 0.8674 - val_loss: 0.0365 - val_rmse: 1.0388\n",
      "Epoch 31/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0281 - rmse: 0.8615 - val_loss: 0.0370 - val_rmse: 1.0536\n",
      "Epoch 32/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0279 - rmse: 0.8567 - val_loss: 0.0367 - val_rmse: 1.0451\n",
      "Epoch 33/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0276 - rmse: 0.8461 - val_loss: 0.0368 - val_rmse: 1.0446\n",
      "Epoch 34/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0275 - rmse: 0.8482 - val_loss: 0.0368 - val_rmse: 1.0474\n",
      "Epoch 35/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0274 - rmse: 0.8473 - val_loss: 0.0376 - val_rmse: 1.0691\n",
      "Epoch 36/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0274 - rmse: 0.8492 - val_loss: 0.0365 - val_rmse: 1.0399\n",
      "Epoch 37/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0270 - rmse: 0.8369 - val_loss: 0.0373 - val_rmse: 1.0651\n",
      "Epoch 38/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0268 - rmse: 0.8309 - val_loss: 0.0369 - val_rmse: 1.0499\n",
      "Epoch 39/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0267 - rmse: 0.8271 - val_loss: 0.0373 - val_rmse: 1.0628\n",
      "Epoch 40/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0268 - rmse: 0.8302 - val_loss: 0.0377 - val_rmse: 1.0647\n",
      "Epoch 41/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0264 - rmse: 0.8257 - val_loss: 0.0376 - val_rmse: 1.0656\n",
      "Epoch 42/75\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0263 - rmse: 0.8183 - val_loss: 0.0376 - val_rmse: 1.0666\n",
      "Epoch 43/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0260 - rmse: 0.8098 - val_loss: 0.0374 - val_rmse: 1.0625\n",
      "Epoch 44/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0260 - rmse: 0.8134 - val_loss: 0.0370 - val_rmse: 1.0502\n",
      "Epoch 45/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0258 - rmse: 0.8039 - val_loss: 0.0383 - val_rmse: 1.0787\n",
      "Epoch 46/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0257 - rmse: 0.8097 - val_loss: 0.0380 - val_rmse: 1.0767\n",
      "Epoch 47/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0260 - rmse: 0.8115 - val_loss: 0.0376 - val_rmse: 1.0646\n",
      "Epoch 48/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0254 - rmse: 0.8001 - val_loss: 0.0372 - val_rmse: 1.0479\n",
      "Epoch 49/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0254 - rmse: 0.8013 - val_loss: 0.0373 - val_rmse: 1.0570\n",
      "Epoch 50/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0251 - rmse: 0.7938 - val_loss: 0.0376 - val_rmse: 1.0621\n",
      "Epoch 51/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0253 - rmse: 0.7948 - val_loss: 0.0381 - val_rmse: 1.0765\n",
      "Epoch 52/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0251 - rmse: 0.7903 - val_loss: 0.0381 - val_rmse: 1.0766\n",
      "Epoch 53/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0249 - rmse: 0.7862 - val_loss: 0.0379 - val_rmse: 1.0692\n",
      "Epoch 54/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0249 - rmse: 0.7848 - val_loss: 0.0386 - val_rmse: 1.0925\n",
      "Epoch 55/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0248 - rmse: 0.7827 - val_loss: 0.0379 - val_rmse: 1.0726\n",
      "Epoch 56/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0248 - rmse: 0.7834 - val_loss: 0.0385 - val_rmse: 1.0902\n",
      "Epoch 57/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0245 - rmse: 0.7746 - val_loss: 0.0386 - val_rmse: 1.0964\n",
      "Epoch 58/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0244 - rmse: 0.7738 - val_loss: 0.0378 - val_rmse: 1.0751\n",
      "Epoch 59/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0243 - rmse: 0.7723 - val_loss: 0.0386 - val_rmse: 1.0973\n",
      "Epoch 60/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0241 - rmse: 0.7704 - val_loss: 0.0382 - val_rmse: 1.0851\n",
      "Epoch 61/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0240 - rmse: 0.7598 - val_loss: 0.0381 - val_rmse: 1.0764\n",
      "Epoch 62/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0237 - rmse: 0.7604 - val_loss: 0.0391 - val_rmse: 1.1086\n",
      "Epoch 63/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0239 - rmse: 0.7621 - val_loss: 0.0385 - val_rmse: 1.0887\n",
      "Epoch 64/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0238 - rmse: 0.7551 - val_loss: 0.0392 - val_rmse: 1.1124\n",
      "Epoch 65/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0235 - rmse: 0.7557 - val_loss: 0.0393 - val_rmse: 1.1106\n",
      "Epoch 66/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0234 - rmse: 0.7515 - val_loss: 0.0388 - val_rmse: 1.0955\n",
      "Epoch 67/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0232 - rmse: 0.7438 - val_loss: 0.0393 - val_rmse: 1.1091\n",
      "Epoch 68/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0230 - rmse: 0.7419 - val_loss: 0.0397 - val_rmse: 1.1211\n",
      "Epoch 69/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0232 - rmse: 0.7438 - val_loss: 0.0389 - val_rmse: 1.1007\n",
      "Epoch 70/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0230 - rmse: 0.7370 - val_loss: 0.0382 - val_rmse: 1.0798\n",
      "Epoch 71/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0229 - rmse: 0.7362 - val_loss: 0.0390 - val_rmse: 1.1014\n",
      "Epoch 72/75\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0226 - rmse: 0.7343 - val_loss: 0.0391 - val_rmse: 1.1063\n",
      "Epoch 73/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0226 - rmse: 0.7260 - val_loss: 0.0389 - val_rmse: 1.0927\n",
      "Epoch 74/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0227 - rmse: 0.7358 - val_loss: 0.0393 - val_rmse: 1.1039\n",
      "Epoch 75/75\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0224 - rmse: 0.7234 - val_loss: 0.0392 - val_rmse: 1.1026\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='rmse',  # Monitorea la pérdida de validación\n",
    "    patience=15,         # Número de epochs sin mejora después del cual el entrenamiento será detenido\n",
    "    restore_best_weights=True  # Restaura los pesos del modelo desde la epoch con la mejor pérdida de validación\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=75, verbose=1, validation_split=0.15, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.022875503129459"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52134184, -2.04956275],\n",
       "       [ 0.37837541,  0.03100809],\n",
       "       [ 0.6496745 ,  0.99063334],\n",
       "       ...,\n",
       "       [-0.124802  , -1.54911533],\n",
       "       [ 1.49614491,  1.39923182],\n",
       "       [ 0.58290435,  0.42737294]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0405 - rmse: 1.1570\n",
      "Loss on test data: [0.040507722645998, 1.1570314168930054]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Loss on test data: {loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
