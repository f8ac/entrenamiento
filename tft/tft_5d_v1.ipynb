{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/copper_returns_5d_final.csv')\n",
    "features = data.drop(columns=['Date', 'LMCADY_acu_5d', 'LMCADY_std_5d'])  # Asegúrate de excluir también la variable objetivo de los features\n",
    "target = data['LMCADY_acu_5d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMCADS03</th>\n",
       "      <th>LMCADY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>SPX</th>\n",
       "      <th>BCOM</th>\n",
       "      <th>MXWD</th>\n",
       "      <th>XAU</th>\n",
       "      <th>XAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>0.009327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>-0.005829</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>-0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>-0.004022</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002514</td>\n",
       "      <td>-0.002130</td>\n",
       "      <td>-0.005961</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.006740</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.033895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>-0.008826</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>-0.006092</td>\n",
       "      <td>-0.013172</td>\n",
       "      <td>-0.026096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>-0.009774</td>\n",
       "      <td>-0.009724</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>-0.018041</td>\n",
       "      <td>-0.010309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>-0.005850</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.020312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>-0.010746</td>\n",
       "      <td>-0.010210</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>-0.021980</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>-0.018378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>-0.013035</td>\n",
       "      <td>-0.013388</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.014186</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.014804</td>\n",
       "      <td>-0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>-0.018868</td>\n",
       "      <td>-0.019639</td>\n",
       "      <td>-0.010682</td>\n",
       "      <td>-0.032133</td>\n",
       "      <td>-0.025019</td>\n",
       "      <td>-0.022941</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>-0.007887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5539 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LMCADS03    LMCADY       DXY       SPX      BCOM      MXWD       XAU  \\\n",
       "0     0.001241  0.001047 -0.000767  0.002808  0.006127  0.001182 -0.003199   \n",
       "1    -0.000733 -0.000182  0.002015  0.003064 -0.005829  0.002399 -0.002942   \n",
       "2     0.009474  0.009322 -0.004022  0.001404  0.007491  0.002585  0.007338   \n",
       "3    -0.002514 -0.002130 -0.005961 -0.003226 -0.001953 -0.006740  0.002320   \n",
       "4     0.005432  0.005893  0.004159 -0.008826  0.003441 -0.006092 -0.013172   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5534 -0.009774 -0.009724  0.006872  0.014287 -0.004085  0.014765 -0.018041   \n",
       "5535  0.004627  0.004489 -0.005850  0.006588  0.002701  0.008892  0.011519   \n",
       "5536 -0.010746 -0.010210  0.004903 -0.021980  0.016248 -0.018378  0.000000   \n",
       "5537 -0.013035 -0.013388  0.004977  0.000484 -0.014186 -0.003775 -0.014804   \n",
       "5538 -0.018868 -0.019639 -0.010682 -0.032133 -0.025019 -0.022941  0.005780   \n",
       "\n",
       "           XAG  \n",
       "0     0.009327  \n",
       "1    -0.000409  \n",
       "2     0.002853  \n",
       "3     0.033895  \n",
       "4    -0.026096  \n",
       "...        ...  \n",
       "5534 -0.010309  \n",
       "5535  0.020312  \n",
       "5536 -0.001531  \n",
       "5537 -0.014724  \n",
       "5538 -0.007887  \n",
       "\n",
       "[5539 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.88174336e-02,  7.44158059e-02, -1.61553556e-01, ...,\n",
       "         1.40393504e-01, -2.72839869e-01,  4.81635337e-01],\n",
       "       [-3.41047918e-02, -2.12838525e-04,  4.18921718e-01, ...,\n",
       "         2.63621263e-01, -2.48888913e-01, -1.54865105e-02],\n",
       "       [ 6.01515341e-01,  5.77035466e-01, -8.40686743e-01, ...,\n",
       "         2.82472734e-01,  7.09955572e-01,  1.51088802e-01],\n",
       "       ...,\n",
       "       [-6.57712049e-01, -6.09357555e-01,  1.02160791e+00, ...,\n",
       "        -1.83950901e+00,  2.55342740e-02, -7.27844599e-02],\n",
       "       [-8.00281396e-01, -8.02392606e-01,  1.03697816e+00, ...,\n",
       "        -3.61342573e-01, -1.35527210e+00, -7.46369564e-01],\n",
       "       [-1.16351169e+00, -1.18211667e+00, -2.23029805e+00, ...,\n",
       "        -2.30137329e+00,  5.64594036e-01, -3.97293980e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034782023369004565"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar desviacion estandar de target\n",
    "target.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset   = TensorDataset(torch.tensor(X_train, dtype=torch.float), torch.tensor(y_train.values, dtype=torch.float))\n",
    "val_dataset     = TensorDataset(torch.tensor(X_val, dtype=torch.float), torch.tensor(y_val.values, dtype=torch.float))\n",
    "train_loader    = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader      = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5539, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=features.shape[1], nhead=4, dim_feedforward=128)\n",
    "        self.encoder = nn.TransformerEncoder(self.transformer_layer, num_layers=1)\n",
    "        self.regressor = nn.Linear(features.shape[1], 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gapuj\\miniconda3\\envs\\cafe\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: c:\\Users\\gapuj\\repositories\\GitHub\\tesis\\entrenamiento\\tft\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                    | Params\n",
      "--------------------------------------------------------------\n",
      "0 | transformer_layer | TransformerEncoderLayer | 2.5 K \n",
      "1 | encoder           | TransformerEncoder      | 2.5 K \n",
      "2 | regressor         | Linear                  | 9     \n",
      "--------------------------------------------------------------\n",
      "5.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gapuj\\miniconda3\\envs\\cafe\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\gapuj\\miniconda3\\envs\\cafe\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "C:\\Users\\gapuj\\AppData\\Local\\Temp\\ipykernel_7224\\3376634985.py:22: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y)\n",
      "c:\\Users\\gapuj\\miniconda3\\envs\\cafe\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/70 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gapuj\\AppData\\Local\\Temp\\ipykernel_7224\\3376634985.py:16: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 70/70 [00:00<00:00, 118.51it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gapuj\\AppData\\Local\\Temp\\ipykernel_7224\\3376634985.py:16: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 70/70 [00:00<00:00, 100.19it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gapuj\\AppData\\Local\\Temp\\ipykernel_7224\\3376634985.py:22: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 70/70 [00:00<00:00, 129.36it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 70/70 [00:00<00:00, 76.01it/s, v_num=0] \n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel()\n",
    "trainer = pl.Trainer(max_epochs=50)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gapuj\\AppData\\Local\\Temp\\ipykernel_7224\\1503390093.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  y_val_pred = [model(torch.tensor([x], dtype=torch.float)).item() for x in X_val]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE final en el conjunto de validación: 0.03637988260735615\n",
      "Stdev de valores reales: 0.034027450312969415\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = [model(torch.tensor([x], dtype=torch.float)).item() for x in X_val]\n",
    "final_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "print(f\"RMSE final en el conjunto de validación: {final_rmse}\")\n",
    "print(\"Stdev de valores reales: {}\".format(y_val.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
